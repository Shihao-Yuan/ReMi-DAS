{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0c061b",
   "metadata": {},
   "source": [
    "# ReMi-DAS: Refraction Microtremor Processing for DAS\n",
    "\n",
    "This Jupyter notebook demonstrates the application of the **ReMi-DAS** workflow for shear-wave velocity profiling using DAS data. The notebook guides users through a series of processing steps adapted from conventional Refraction Microtremor (ReMi) techniques, including:\n",
    "\n",
    "- Reading and preprocessing DAS data\n",
    "- Slowness-frequency (p-f) transformation\n",
    "- Extraction of Rayleigh wave dispersion curves\n",
    "\n",
    "The ReMi-DAS implementation uses the functionality of the [**DASCore**](https://github.com/DASDAE/dascore) package for signal processing.\n",
    "\n",
    "### References\n",
    "\n",
    "- McMechan, G.A. and Yedlin, M.J., 1981. Analysis of dispersive waves by wave field transformation. *Geophysics*, 46(6), pp.869-874.  \n",
    "- Louie, J.N., 2001. Faster, better: shear-wave velocity to 100 meters depth from refraction microtremor arrays. *BSSA*, 91(2), pp.347-364. \n",
    "- Chambers, D., Jin, G., Tourei, A., Issah, A.H.S., Lellouch, A., Martin, E.R., Zhu, D., Girard, A.J., Yuan, S., Cullison, T. and Snyder, T., 2024. Dascore: A python library for distributed fiber optic sensing. *Seismica*, 3(2), pp.10-26443.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733731b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages installation if not already installed\n",
    "\n",
    "# !pip install dascore --upgrade --quiet\n",
    "# !pip install PyQt5 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9155e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "import dascore as dc\n",
    "from dascore.units import Hz\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Use Qt backend for interactive plots\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a071b00",
   "metadata": {},
   "source": [
    "### Reading and Preprocessing DAS Data\n",
    "\n",
    "*Note: You can skip this section if you're using the provided example dataset (`example.h5`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path and filename for DAS data\n",
    "folder_path = 'Path/To/Your/DAS/Folder'  # Replace with your actual folder path\n",
    "filename = 'data.hdf5'  # Replace with your actual DAS file name\n",
    "\n",
    "full_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Read and preprocess data\n",
    "pa = dc.spool(full_path)\n",
    "pa_fil = (\n",
    "    pa[0]\n",
    "    .set_units(\"1/s\", distance=\"m\", time=\"s\")  # Set physical units\n",
    "    .detrend(\"time\")                           # Remove linear trend\n",
    "    .decimate(time=20)                         # Downsample in time\n",
    "    .taper(time=0.05)                          # Apply taper in time\n",
    "    .pass_filter(time=(1 * Hz, 49 * Hz))       # Bandpass filter \n",
    "    .select(distance=(102, 222), samples=True) # Select a distance range\n",
    "    .transpose('distance', 'time')             \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d786ac",
   "metadata": {},
   "source": [
    "### Using the Example Preprocessed Data\n",
    "\n",
    "The file `example.h5` contains data that has already been preprocessed using the steps described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5264b6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='time', ylabel='distance(m)'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the preprocessed example data and visualize it\n",
    "pa_fil = dc.spool('./example.h5')\n",
    "\n",
    "# Plot the preprocessed data\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "pa_fil[0].viz.waterfall(ax=ax,scale=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6bdf36",
   "metadata": {},
   "source": [
    "### Velocity Spectral (p-f) Analysis\n",
    "\n",
    "This section performs slowness-frequency transformation on the DAS data.  \n",
    "The workflow includes:\n",
    "- Chunking the data into overlapping time windows.\n",
    "- Applying tapers in both time and distance to reduce edge effects.\n",
    "- Performing a tau-p (slant stack) transform to map the data into the slowness domain.\n",
    "- Computing the discrete Fourier transform (DFT) along the time axis to obtain the frequency content for each slowness.\n",
    "- The resulting spectra are used for subsequent stacking, normalization, and dispersion curve picking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6322b102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcdc5a0a95b4c6f971fa70053474560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df051fbf66b64defb0534700d1bf6706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ac019dd18f45318cb09ce062848aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1e64ab57c6411590b74fa104d04c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a53a44db794626a44eaf0cc1e2b260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a874cd1599dd4375b8fdd419b2490a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8e93a203a8465a9c0ed276fc420667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274f733cef1e4ddaaa231a235e50085b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define processing functions for each step\n",
    "def taper(patch, time, window_type):\n",
    "    \"\"\"Apply a taper along the time axis.\"\"\"\n",
    "    return patch.taper(time=0.1, window_type=window_type)\n",
    "\n",
    "def taper_d(patch, distance, window_type):\n",
    "    \"\"\"Apply a taper along the distance axis.\"\"\"\n",
    "    return patch.taper(distance=0.1, window_type=window_type)\n",
    "\n",
    "def taup(patch, velocities):\n",
    "    \"\"\"Apply tau-p (slant stack) transform with given velocities.\"\"\"\n",
    "    return patch.tau_p(velocities)\n",
    "\n",
    "def dft(patch, dim=\"time\"):\n",
    "    \"\"\"Apply discrete Fourier transform along the specified dimension.\"\"\"\n",
    "    return patch.dft(dim=\"time\", real=True)\n",
    "\n",
    "\n",
    "# Process the data step by step\n",
    "sp_fil = dc.spool(pa_fil)\n",
    "\n",
    "# Chunk the data into segments of 30 seconds with 10 seconds overlap\n",
    "sp_fil_chunked = sp_fil.chunk(time=30, overlap=10)\n",
    "\n",
    "# Apply tapering in time\n",
    "sp_fil_chunked_taper = dc.spool(\n",
    "    sp_fil_chunked.map(taper, time=0.1, window_type=\"hann\")\n",
    ")\n",
    "\n",
    "# Apply tapering in distance\n",
    "sp_fil_chunked_taper_d = dc.spool(\n",
    "    sp_fil_chunked_taper.map(taper_d, distance=0.1, window_type=\"hann\")\n",
    ")\n",
    "\n",
    "# Apply tau-p transform with specified velocities\n",
    "sp_fil_chunked_taper_taup = dc.spool(\n",
    "    sp_fil_chunked_taper_d.map(taup, velocities=np.arange(100, 800, 20))\n",
    ")\n",
    "\n",
    "# Apply discrete Fourier transform along the time dimension\n",
    "sp_fil_chunked_taper_taup_dft = dc.spool(\n",
    "    sp_fil_chunked_taper_taup.map(dft, dim=\"time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4577759a",
   "metadata": {},
   "source": [
    "### Spectral normalization and stacking\n",
    "\n",
    "This section computes the normalized and stacked power spectrum across all data chunks.  \n",
    "For each chunk, the code:\n",
    "- Calculates the power spectrum (magnitude squared of the DFT).\n",
    "- Splits the spectrum into positive and negative slowness components and sums them to enforce symmetry.\n",
    "- Normalizes each frequency by the average amplitude across slowness.\n",
    "- Stacks (sums) the normalized spectra from all chunks to enhance coherent features and suppress noise.\n",
    "\n",
    "The result, `summed_avg_stack`, is a 2D array representing the normalized, stacked power as a function of frequency and slowness, ready for visualization and dispersion analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7941b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of frequency bins and midpoint\n",
    "n_freq = sp_fil_chunked_taper_taup_dft[0].data.shape[0]\n",
    "half = n_freq // 2\n",
    "\n",
    "# Initialize the stack for the averaged, normalized spectra\n",
    "if n_freq % 2 == 0:\n",
    "    summed_avg_stack = np.zeros((half, sp_fil_chunked_taper_taup_dft[0].data.shape[1]))\n",
    "else:\n",
    "    summed_avg_stack = np.zeros((half + 1, sp_fil_chunked_taper_taup_dft[0].data.shape[1]))\n",
    "\n",
    "# Loop through each chunked patch and sum normalized power spectra\n",
    "for i, patch in enumerate(sp_fil_chunked_taper_taup_dft):\n",
    "    \n",
    "    # Compute power spectrum \n",
    "    power_spectrum = (patch.data * np.conj(patch.data)).real\n",
    "\n",
    "    if n_freq % 2 == 0:\n",
    "        # Split into negative and positive slowness components\n",
    "        # Even: includes Nyquist frequency\n",
    "        neg = power_spectrum[:half,:]\n",
    "        pos = power_spectrum[half:,:]\n",
    "        neg_flipped  = np.flipud(neg)\n",
    "        summed = pos + neg_flipped\n",
    "    else:\n",
    "        # Split into negative and positive slowness components\n",
    "        # Odd\n",
    "        pos = power_spectrum[:half+1]\n",
    "        neg = power_spectrum[half+1:]\n",
    "        neg_flipped  = np.flipud(neg)\n",
    "        summed = pos + neg_flipped[:pos.shape[0]]\n",
    "\n",
    "    # Normalize by the average across slowness for each frequency\n",
    "    avg = np.sum(summed, axis=0) / len(summed)\n",
    "    summed_avg = summed/avg\n",
    "\n",
    "    # Accumulate the normalized spectra\n",
    "    summed_avg_stack = summed_avg_stack + summed_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213885d5",
   "metadata": {},
   "source": [
    "### Rayleigh Phase-Velocity Dispersion Picking\n",
    "\n",
    "This section enables interactive picking of the Rayleigh wave dispersion curve from the stacked slowness-frequency (p-f) spectrum.  \n",
    "\n",
    "- The normalized and stacked power spectrum is displayed as an image, with frequency on the x-axis and apparent velocity on the y-axis.\n",
    "- The user manually selects points along the visible dispersion curve by clicking on the plot; pressing Enter finishes the selection.\n",
    "- The picked points are sorted and interpolated using a cubic spline to produce a smooth dispersion curve.\n",
    "- The result is visualized by overlaying the picked points and the interpolated curve on the power spectrum image.\n",
    "\n",
    "This process allows for extraction of the fundamental mode Rayleigh wave phase velocity dispersion curve for subsequent 1D shear-wave velocity inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb255c3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get frequency and slowness arrays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m freq \u001b[38;5;241m=\u001b[39m sp_fil_chunked_taper_taup_dft[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_coord(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mft_time\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[43msummed\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m      3\u001b[0m slowness \u001b[38;5;241m=\u001b[39m sp_fil_chunked_taper_taup_dft[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_coord(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslowness\u001b[39m\u001b[38;5;124m'\u001b[39m)[half:]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create figure\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summed' is not defined"
     ]
    }
   ],
   "source": [
    "# Get frequency and slowness arrays\n",
    "freq = sp_fil_chunked_taper_taup_dft[0].get_coord('ft_time')[:summed.shape[1]]\n",
    "slowness = sp_fil_chunked_taper_taup_dft[0].get_coord('slowness')[half:]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "extent = [freq[0], freq[-1], 1/slowness[0], 1/slowness[-1]] # Frequency and apparent velocity extent\n",
    "im = ax.imshow(\n",
    "    summed_avg_stack**2,\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    extent=extent,\n",
    "    cmap='plasma',\n",
    "    vmin=0,\n",
    "    vmax=np.max(summed_avg_stack**2)*0.02  # Adjust for better visibility\n",
    ")\n",
    "ax.set_xlabel('Frequency (Hz)', fontsize=14)\n",
    "ax.set_ylabel('Apparent Velocity (m/s)', fontsize=14)\n",
    "ax.set_title('Click to pick points, then press Enter', fontsize=14)\n",
    "ax.set_xlim(1, 20)\n",
    "ax.set_ylim(100, 600)\n",
    "fig.colorbar(im, ax=ax, label='Amplitude')\n",
    "\n",
    "# Pick points on that same figure\n",
    "print(\"Click to pick points along the dispersion curve. Press Enter when done.\")\n",
    "picked = fig.ginput(n=-1, timeout=0)  # block until Enter\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "picked = np.array(picked)\n",
    "if picked.shape[0] < 2:\n",
    "    print(\"Not enough points picked for interpolation.\")\n",
    "else:\n",
    "    # Sort and interpolate\n",
    "    picked = picked[np.argsort(picked[:, 0])]\n",
    "    cs = CubicSpline(picked[:, 0], picked[:, 1])\n",
    "    freq_interp = np.linspace(picked[:, 0].min(), picked[:, 0].max(), 200)\n",
    "    velocity_interp = cs(freq_interp)\n",
    "\n",
    "    # Plot result with cubic spline interpolation\n",
    "    fig2, ax2 = plt.subplots(figsize=(10, 5))\n",
    "    im2 = ax2.imshow(\n",
    "        summed_avg_stack**2,\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        extent=extent,\n",
    "        cmap='plasma',\n",
    "        vmin=0,\n",
    "        vmax=np.max(summed_avg_stack**2)*0.02 \n",
    "    )\n",
    "    ax2.set_xlabel('Frequency (Hz)', fontsize=14)\n",
    "    ax2.set_ylabel('Apparent Velocity (m/s)', fontsize=14)\n",
    "    ax2.set_title('Manual Picked Dispersion and Cubic Spline Interpolation', fontsize=14)\n",
    "    ax2.set_xlim(1, 20)\n",
    "    ax2.set_ylim(100, 600)\n",
    "    fig2.colorbar(im2, ax=ax2, label='Amplitude')\n",
    "    ax2.plot(picked[:, 0], picked[:, 1], 'ro', label='Picked Points')\n",
    "    ax2.plot(freq_interp, velocity_interp, 'b-', linewidth=2, label='Cubic Spline')\n",
    "    ax2.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddebd354",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'picked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m      7\u001b[0m extent \u001b[38;5;241m=\u001b[39m [freq[\u001b[38;5;241m0\u001b[39m], freq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mslowness[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mslowness[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],]\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[1;32m      9\u001b[0m     summed_avg_stack\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     10\u001b[0m     aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     vmax\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(summed_avg_stack\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.02\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mpicked\u001b[49m[:, \u001b[38;5;241m0\u001b[39m], picked[:, \u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mro\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPicked Points\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(freq_interp, velocity_interp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb-\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCubic Spline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency (Hz)\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'picked' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot static image of the summed power spectrum\n",
    "# Get frequency and slowness arrays\n",
    "freq = sp_fil_chunked_taper_taup_dft[0].get_coord('ft_time')[:summed.shape[1]]\n",
    "slowness = sp_fil_chunked_taper_taup_dft[0].get_coord('slowness')[half:]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "extent = [freq[0], freq[-1],  1/slowness[0], 1/slowness[-1],]\n",
    "plt.imshow(\n",
    "    summed_avg_stack**2,\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    extent=extent,\n",
    "    cmap='plasma',\n",
    "    vmin=0,\n",
    "    vmax=np.max(summed_avg_stack**2)*0.02\n",
    ")\n",
    "plt.plot(picked[:, 0], picked[:, 1], 'ro', label='Picked Points')\n",
    "plt.plot(freq_interp, velocity_interp, 'b-', linewidth=2, label='Cubic Spline')\n",
    "plt.xlabel('Frequency (Hz)',fontsize=14)\n",
    "plt.ylabel('Apparent Velocity (m/s)',fontsize=14)\n",
    "plt.title('Summed Power Spectrum',fontsize=14)\n",
    "plt.colorbar(label='Amplitude')\n",
    "plt.xlim(1,20)\n",
    "plt.ylim(100,600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523fbd7",
   "metadata": {},
   "source": [
    "### Correlation-Enhanced ReMi (Ce-ReMi) for DAS\n",
    "\n",
    "This section implements a fast correlation-domain upgrade to ReMi using either MVDR (Capon) or coherence-weighted Bartlett beamforming on a linear DAS array.\n",
    "\n",
    "Workflow:\n",
    "- Windowing + QC (optional lightweight checks)\n",
    "- Phase-only/whitened normalization per channel in frequency\n",
    "- Cross-spectral matrix R(f) via Welch-style averaging over accepted windows\n",
    "- Signed-slowness steering and adaptive power computation\n",
    "- Frequency stacking to form a sharp f–p (or f–v) image\n",
    "\n",
    "Notes:\n",
    "- Efficient: one R(f) inversion per frequency (reused for all slownesses)\n",
    "- Scales to DAS: distance-decimation and subarray MVDR are supported\n",
    "- You can keep the same picking workflow (manual or automated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90905475",
   "metadata": {},
   "source": [
    "### Ce-ReMi using existing chunk/map structure (spool-integrated)\n",
    "\n",
    "This variant reuses your `sp_fil -> chunk -> taper(time) -> taper(distance)` pipeline.\n",
    "It accumulates cross-spectral matrices across chunks and then performs MVDR/coherence beamforming over a slowness grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32f4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DASCore Patch ⚡\n",
       "---------------\n",
       "➤ Coordinates (distance: 120, time: 2999)\n",
       "    *distance: CoordRange( min: 5.03e+02 max: 6e+02 step: 0.817 shape: (120,) dtype: float64 units: m )\n",
       "    *time: CoordRange( min: 2024-08-18T22:58:07.349438464 max: 2024-08-18T22:58:37.329918144 step: 0.01000016s shape: (2999,) dtype: datetime64[ns] units: s )\n",
       "➤ Data (float64, units: 1.0 / s)\n",
       "   [[-0.000e+00  0.000e+00  0.000e+00 ...  0.000e+00  0.000e+00  0.000e+00]\n",
       "    [ 0.000e+00  6.465e-17  2.793e-16 ... -3.180e-12  3.674e-13 -0.000e+00]\n",
       "    [-0.000e+00 -4.399e-17 -1.998e-16 ...  3.400e-11 -1.371e-11 -0.000e+00]\n",
       "    ...\n",
       "    [ 0.000e+00  3.417e-16  1.108e-15 ...  1.698e-12 -1.063e-13  0.000e+00]\n",
       "    [ 0.000e+00  2.186e-16  7.023e-16 ...  5.980e-14  4.384e-14 -0.000e+00]\n",
       "    [-0.000e+00 -0.000e+00 -0.000e+00 ... -0.000e+00 -0.000e+00 -0.000e+00]]\n",
       "➤ Attributes\n",
       "    data_type: strain_rate\n",
       "    data_units: 1 / s\n",
       "    instrument_id: TrebleIISystem04\n",
       "    history: (\"set_units(data_units='1/s',distance='m',time='s')\", \"detrend(dim='time',type='linear')\", \"decimate(copy='True',filter_type='iir',time='20')\", \"taper(time='0.05',window_type='hann')\", \"pass_filter(corners='4',time='(1 Hz,49 Hz)',zerophase='True')\", \"taper(time='0.1',window_type='hann')\", \"taper(distance='0.1',window_type='hann')\")\n",
       "    gauge_length: 1.63\n",
       "    pulse_length: 1.63\n",
       "    pulse_rate: 4.82e+04"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7645ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce-ReMi: accepted windows total = 100, freq bins used = 580\n"
     ]
    }
   ],
   "source": [
    "# --- Build cross-spectral matrices R(f) from chunked spool ---\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "from scipy.signal import get_window\n",
    "\n",
    "# Fallback definitions if not imported earlier in this notebook\n",
    "try:\n",
    "    compute_window_metrics\n",
    "except NameError:\n",
    "    def compute_window_metrics(x):\n",
    "        pow2 = np.mean(x**2, axis=1) + 1e-12\n",
    "        pow4 = np.mean(x**4, axis=1)\n",
    "        krt = np.median(pow4 / (pow2**2 + 1e-18))\n",
    "        X = np.abs(rfft(x, axis=1)) + 1e-12\n",
    "        gmean = np.exp(np.mean(np.log(X), axis=1))\n",
    "        amean = np.mean(X, axis=1) + 1e-12\n",
    "        flat = np.median(gmean / amean)\n",
    "        med = np.median(x, axis=0)\n",
    "        n = med.size\n",
    "        n_sta = max(1, n // 50)\n",
    "        n_lta = max(1, n // 5)\n",
    "        sta = np.convolve(np.abs(med), np.ones(n_sta)/n_sta, mode='same')\n",
    "        lta = np.convolve(np.abs(med), np.ones(n_lta)/n_lta, mode='same') + 1e-12\n",
    "        stalta = float(np.nanmax(sta / lta))\n",
    "        return krt, flat, stalta\n",
    "\n",
    "try:\n",
    "    phase_only_normalize\n",
    "except NameError:\n",
    "    def phase_only_normalize(X):\n",
    "        mag = np.abs(X) + 1e-12\n",
    "        return X / mag\n",
    "\n",
    "try:\n",
    "    prewhiten_channels\n",
    "except NameError:\n",
    "    def prewhiten_channels(X):\n",
    "        amp = np.maximum(np.median(np.abs(X), axis=1, keepdims=True), 1e-12)\n",
    "        return X / amp\n",
    "\n",
    "# Extract distance/time axes and fs from the already-processed spool\n",
    "patch0 = sp_fil_chunked_taper_d[0]\n",
    "dist_axis = np.asarray(patch0.get_coord('distance'))\n",
    "# DASCore time is datetime64; convert to seconds before computing fs.\n",
    "time_vals = np.asarray(patch0.get_coord('time')).astype('datetime64[ns]')\n",
    "# Use the median delta in nanoseconds; convert to seconds\n",
    "dt_sec = np.median(np.diff(time_vals).astype('timedelta64[ns]').astype(np.int64)) * 1e-9\n",
    "fs_chunk = 1.0 / float(dt_sec)\n",
    "\n",
    "# Configure Ce-ReMi parameters (reuse earlier choices if desired)\n",
    "win_len_s_ce = 20.0\n",
    "step_s_ce = 10.0\n",
    "qc_thresholds_ce = (20.0, 0.6, 4.0)\n",
    "\n",
    "p_min, p_max, p_step = 1/1000.0, 1/100.0, 1/4000.0\n",
    "slowness_grid_ce = np.arange(p_min, p_max + 1e-9, p_step)\n",
    "\n",
    "fmin_ce, fmax_ce = 1.0, 30.0\n",
    "beam_method_ce = 'mvdr'  # 'mvdr' or 'coh'\n",
    "\n",
    "# Initialize accumulators lazily after first chunk\n",
    "R_acc = None\n",
    "n_used_total = 0\n",
    "\n",
    "for patch in sp_fil_chunked_taper_d:\n",
    "    # Time-domain data [distance, time]\n",
    "    X = np.asarray(patch.data)\n",
    "    if X.shape[0] < X.shape[1]:\n",
    "        data_chunk = X\n",
    "    else:\n",
    "        data_chunk = X.T  # [n_channels, n_samples]\n",
    "\n",
    "    n_channels, n_samples = data_chunk.shape\n",
    "\n",
    "    n_win = int(win_len_s_ce * fs_chunk)\n",
    "    n_step = int(step_s_ce * fs_chunk)\n",
    "    if n_win <= 8 or n_samples < n_win:\n",
    "        continue\n",
    "\n",
    "    tap = get_window('hann', n_win, fftbins=True).astype(float)\n",
    "\n",
    "    # Slide windows inside this chunk\n",
    "    for start in range(0, n_samples - n_win + 1, n_step):\n",
    "        seg = data_chunk[:, start:start+n_win]\n",
    "        # QC\n",
    "        krt, flat, stalta = compute_window_metrics(seg)\n",
    "        krt_max, flat_min, stalta_max = qc_thresholds_ce\n",
    "        if not (krt < krt_max and flat > flat_min and stalta < stalta_max):\n",
    "            continue\n",
    "\n",
    "        seg_w = seg * tap\n",
    "        Xf = rfft(seg_w, axis=1)  # [n_channels, n_freq]\n",
    "        Xf = prewhiten_channels(Xf)\n",
    "        Xf = phase_only_normalize(Xf)\n",
    "\n",
    "        if R_acc is None:\n",
    "            n_freq = Xf.shape[1]\n",
    "            R_acc = np.zeros((n_freq, n_channels, n_channels), dtype=np.complex128)\n",
    "            freqs_ce = rfftfreq(n_win, d=1.0/fs_chunk)\n",
    "\n",
    "        if Xf.shape[1] != R_acc.shape[0]:\n",
    "            # Skip if inconsistent frequency length (shouldn't happen with fixed window)\n",
    "            continue\n",
    "\n",
    "        Xf_fcn = np.transpose(Xf, (1,0))  # [n_freq, n_channels]\n",
    "        R_acc += Xf_fcn[:, :, None] * np.conjugate(Xf_fcn[:, None, :])\n",
    "        n_used_total += 1\n",
    "\n",
    "# If no windows passed QC, fall back to using all windows without QC to ensure non-empty output\n",
    "if n_used_total == 0:\n",
    "    R_acc = None\n",
    "    for patch in sp_fil_chunked_taper_d:\n",
    "        X = np.asarray(patch.data)\n",
    "        data_chunk = X if X.shape[0] < X.shape[1] else X.T\n",
    "        n_channels, n_samples = data_chunk.shape\n",
    "        n_win = int(win_len_s_ce * fs_chunk)\n",
    "        if n_samples < n_win:\n",
    "            continue\n",
    "        tap = get_window('hann', n_win, fftbins=True).astype(float)\n",
    "        seg = data_chunk[:, :n_win]\n",
    "        seg_w = seg * tap\n",
    "        Xf = rfft(seg_w, axis=1)\n",
    "        Xf = prewhiten_channels(Xf)\n",
    "        Xf = phase_only_normalize(Xf)\n",
    "        if R_acc is None:\n",
    "            n_freq = Xf.shape[1]\n",
    "            R_acc = np.zeros((n_freq, n_channels, n_channels), dtype=np.complex128)\n",
    "            freqs_ce = rfftfreq(n_win, d=1.0/fs_chunk)\n",
    "        Xf_fcn = np.transpose(Xf, (1,0))\n",
    "        R_acc += Xf_fcn[:, :, None] * np.conjugate(Xf_fcn[:, None, :])\n",
    "        n_used_total = 1\n",
    "        break\n",
    "\n",
    "# Normalize\n",
    "R_acc = R_acc / max(1, n_used_total)\n",
    "\n",
    "# Restrict frequency band\n",
    "fmask_ce = (freqs_ce >= fmin_ce) & (freqs_ce <= fmax_ce)\n",
    "R_ce = R_acc[fmask_ce]\n",
    "freqs_sel_ce = freqs_ce[fmask_ce]\n",
    "print(f\"Ce-ReMi: accepted windows total = {n_used_total}, freq bins used = {freqs_sel_ce.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e1deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Beamforming with signed slowness using existing dist_axis ---\n",
    "# Reuse previously defined beamformer helpers from earlier Ce-ReMi section if present.\n",
    "\n",
    "# If helpers are not yet defined in this session, define minimal versions here.\n",
    "try:\n",
    "    steering_vectors\n",
    "except NameError:\n",
    "    def steering_vectors(distance_axis_m, freqs, slowness_s_per_m, sign=+1):\n",
    "        x = distance_axis_m[None, None, :]\n",
    "        f = freqs[:, None, None]\n",
    "        p = (sign * slowness_s_per_m[None, :, None])\n",
    "        phase = -2j * np.pi * f * p * x\n",
    "        return np.exp(phase)\n",
    "\n",
    "try:\n",
    "    mvdr_power\n",
    "except NameError:\n",
    "    def mvdr_power(Rf, A):\n",
    "        N = Rf.shape[0]\n",
    "        Rr = Rf + 1e-3 * np.trace(Rf).real / N * np.eye(N)\n",
    "        try:\n",
    "            RiA = np.linalg.solve(Rr, A.T).T\n",
    "        except np.linalg.LinAlgError:\n",
    "            RiA = A\n",
    "        denom = np.sum(np.conjugate(A) * RiA, axis=1).real + 1e-18\n",
    "        return 1.0 / denom\n",
    "\n",
    "try:\n",
    "    coherence_weighted_bartlett\n",
    "except NameError:\n",
    "    def coherence_weighted_bartlett(Rf, A):\n",
    "        d = np.sqrt(np.clip(np.real(np.diag(Rf)), 1e-12, None))\n",
    "        Dinv = 1.0 / d\n",
    "        Rcorr = (Rf * Dinv[None, :]) * Dinv[:, None]\n",
    "        return np.einsum('pn,nm,pm->p', np.conjugate(A), Rcorr, A).real\n",
    "\n",
    "\n",
    "def compute_fp_spectrum_ce(R, freqs, distance_axis_m, slowness_grid, method='mvdr', sign=+1):\n",
    "    F, N, _ = R.shape\n",
    "    P = slowness_grid.size\n",
    "    S = np.zeros((F, P), dtype=float)\n",
    "    A_all = steering_vectors(distance_axis_m, freqs, slowness_grid, sign=sign)\n",
    "    for k in range(F):\n",
    "        Rf = R[k]\n",
    "        A = A_all[k]\n",
    "        if method == 'mvdr':\n",
    "            S[k] = mvdr_power(Rf, A)\n",
    "        else:\n",
    "            S[k] = coherence_weighted_bartlett(Rf, A)\n",
    "    return S\n",
    "\n",
    "Spos_ce = compute_fp_spectrum_ce(R_ce, freqs_sel_ce, dist_axis, slowness_grid_ce, method=beam_method_ce, sign=+1)\n",
    "Sneg_ce = compute_fp_spectrum_ce(R_ce, freqs_sel_ce, dist_axis, slowness_grid_ce, method=beam_method_ce, sign=-1)\n",
    "\n",
    "Sfp_ce = Spos_ce + Sneg_ce\n",
    "# Protect against degenerate rows\n",
    "row_mean = np.mean(Sfp_ce, axis=1, keepdims=True)\n",
    "row_mean[row_mean == 0] = 1.0\n",
    "Sfp_ce_norm = Sfp_ce / row_mean\n",
    "\n",
    "# Package outputs for downstream use\n",
    "ce_out = {\n",
    "    'freqs': freqs_sel_ce,\n",
    "    'slowness': slowness_grid_ce,\n",
    "    'velocity': 1.0 / slowness_grid_ce,\n",
    "    'power_pf': Sfp_ce_norm,  # [F, P]\n",
    "    'power_pf_pos': Spos_ce,\n",
    "    'power_pf_neg': Sneg_ce,\n",
    "    'R': R_ce,\n",
    "}\n",
    "\n",
    "# Visualization\n",
    "vel_grid_ce = 1.0 / slowness_grid_ce\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "im0 = ax[0].imshow(\n",
    "    Sfp_ce_norm,\n",
    "    aspect='auto', origin='lower',\n",
    "    extent=[slowness_grid_ce[0], slowness_grid_ce[-1], freqs_sel_ce[0], freqs_sel_ce[-1]],\n",
    "    cmap='plasma'\n",
    ")\n",
    "ax[0].set_xlabel('Slowness p (s/m)')\n",
    "ax[0].set_ylabel('Frequency (Hz)')\n",
    "ax[0].set_title(f'Ce-ReMi (chunked) {beam_method_ce.upper()} f–p')\n",
    "fig.colorbar(im0, ax=ax[0])\n",
    "\n",
    "im1 = ax[1].imshow(\n",
    "    Sfp_ce_norm,\n",
    "    aspect='auto', origin='lower',\n",
    "    extent=[vel_grid_ce[-1], vel_grid_ce[0], freqs_sel_ce[0], freqs_sel_ce[-1]],\n",
    "    cmap='plasma'\n",
    ")\n",
    "ax[1].set_xlabel('Velocity v (m/s)')\n",
    "ax[1].set_ylabel('Frequency (Hz)')\n",
    "ax[1].set_title('Ce-ReMi (chunked) f–v')\n",
    "fig.colorbar(im1, ax=ax[1])\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5216d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dispersion image: velocity (y) vs frequency (x) ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prefer ce_out if available\n",
    "if 'ce_out' in globals() and isinstance(ce_out, dict) and 'power_pf' in ce_out:\n",
    "    Sfp = ce_out['power_pf']           # [F, P]\n",
    "    freqs = np.asarray(ce_out['freqs'])\n",
    "    vel = np.asarray(ce_out['velocity'])\n",
    "else:\n",
    "    # Fallback to local variables from Ce-ReMi section\n",
    "    Sfp = Sfp_ce_norm                  # [F, P]\n",
    "    freqs = np.asarray(freqs_sel_ce)\n",
    "    vel = 1.0 / np.asarray(slowness_grid_ce)\n",
    "\n",
    "# Ensure frequency increases left->right\n",
    "if freqs[0] > freqs[-1]:\n",
    "    freqs = freqs[::-1]\n",
    "    Sfp = Sfp[::-1, :]\n",
    "\n",
    "# Map to velocity on y-axis explicitly; no rotation, just transpose to [P, F]\n",
    "S_vy = Sfp.T                           # [P, F]\n",
    "vel_min, vel_max = float(np.min(vel)), float(np.max(vel))\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "im = plt.imshow(\n",
    "    S_vy,\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    extent=[float(freqs[0]), float(freqs[-1]), vel_min, vel_max],\n",
    "    cmap='plasma'\n",
    ")\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Apparent Velocity (m/s)')\n",
    "plt.title('Ce-ReMi dispersion image (Velocity vs Frequency)')\n",
    "plt.colorbar(im, label='Normalized power')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a4ab3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge contrast (mean across freq): ReMi=2.60, Ce-ReMi=1.64\n"
     ]
    }
   ],
   "source": [
    "# --- Comparison: Original ReMi vs Ce-ReMi (Velocity vs Frequency) ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build Original ReMi arrays\n",
    "try:\n",
    "    # Frequencies and slowness from tau-p DFT patch\n",
    "    patch_dft0 = sp_fil_chunked_taper_taup_dft[0]\n",
    "    ft_all = np.asarray(patch_dft0.get_coord('ft_time'))\n",
    "    sl_all = np.asarray(patch_dft0.get_coord('slowness'))\n",
    "    F_re, P_re = summed_avg_stack.shape  # [freq, slowness]\n",
    "    f_re = ft_all[:F_re]\n",
    "    # Follow original indexing convention for positive slowness\n",
    "    half_local = patch_dft0.data.shape[0] // 2\n",
    "    sl_pos = sl_all[half_local:half_local + P_re]\n",
    "    v_re = 1.0 / sl_pos\n",
    "    S_re = np.asarray(summed_avg_stack)\n",
    "    # Orient to [velocity, frequency]\n",
    "    S_re_vy = S_re.T  # [P, F]\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Original ReMi products not available: {e}\")\n",
    "\n",
    "# Build Ce-ReMi arrays\n",
    "if 'ce_out' in globals() and isinstance(ce_out, dict) and 'power_pf' in ce_out:\n",
    "    S_ce = np.asarray(ce_out['power_pf'])   # [F,P]\n",
    "    f_ce = np.asarray(ce_out['freqs'])\n",
    "    v_ce = np.asarray(ce_out['velocity'])\n",
    "    S_ce_vy = S_ce.T                        # [P,F]\n",
    "else:\n",
    "    # Fallback to local variables from Ce-ReMi section\n",
    "    S_ce = np.asarray(Sfp_ce_norm)\n",
    "    f_ce = np.asarray(freqs_sel_ce)\n",
    "    v_ce = 1.0 / np.asarray(slowness_grid_ce)\n",
    "    S_ce_vy = S_ce.T\n",
    "\n",
    "# Ensure frequency increases\n",
    "if f_re[0] > f_re[-1]:\n",
    "    f_re = f_re[::-1]\n",
    "    S_re_vy = S_re_vy[:, ::-1]\n",
    "if f_ce[0] > f_ce[-1]:\n",
    "    f_ce = f_ce[::-1]\n",
    "    S_ce_vy = S_ce_vy[:, ::-1]\n",
    "\n",
    "# Common color scale (robust): 99th percentile across both\n",
    "vmax = np.nanmax([np.percentile(S_re_vy, 99), np.percentile(S_ce_vy, 99)])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13, 5), sharey=False)\n",
    "\n",
    "im0 = ax[0].imshow(\n",
    "    S_re_vy,\n",
    "    aspect='auto', origin='lower',\n",
    "    extent=[float(f_re[0]), float(f_re[-1]), float(v_re[0]), float(v_re[-1])],\n",
    "    cmap='plasma', vmin=0, vmax=float(vmax)\n",
    ")\n",
    "ax[0].set_xlabel('Frequency (Hz)')\n",
    "ax[0].set_ylabel('Apparent Velocity (m/s)')\n",
    "ax[0].set_title('Original ReMi')\n",
    "ax[0].invert_yaxis()\n",
    "fig.colorbar(im0, ax=ax[0], label='Norm. power')\n",
    "\n",
    "im1 = ax[1].imshow(\n",
    "    S_ce_vy,\n",
    "    aspect='auto', origin='lower',\n",
    "    extent=[float(f_ce[0]), float(f_ce[-1]), float(v_ce[0]), float(v_ce[-1])],\n",
    "    cmap='plasma', vmin=0, vmax=float(vmax)\n",
    ")\n",
    "ax[1].set_xlabel('Frequency (Hz)')\n",
    "ax[1].set_ylabel('Apparent Velocity (m/s)')\n",
    "ax[1].set_title('Ce-ReMi (adaptive)')\n",
    "ax[1].invert_yaxis()\n",
    "fig.colorbar(im1, ax=ax[1], label='Norm. power')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Simple quantitative comparison: ridge contrast (peak/median) per frequency\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    rc_re = np.nanmean(np.nanmax(S_re, axis=1) / (np.nanmedian(S_re, axis=1) + 1e-12))\n",
    "    rc_ce = np.nanmean(np.nanmax(S_ce, axis=1) / (np.nanmedian(S_ce, axis=1) + 1e-12))\n",
    "print(f\"Ridge contrast (mean across freq): ReMi={rc_re:.2f}, Ce-ReMi={rc_ce:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c9875",
   "metadata": {},
   "source": [
    "### Synthetic demonstration: Original ReMi vs Correlation-Enhanced ReMi (Ce-ReMi)\n",
    "\n",
    "This section synthesizes linear-array data with a known dispersion curve and non-stationary interference, then compares:\n",
    "- Original ReMi (Bartlett beamforming over slowness)\n",
    "- Ce-ReMi (correlation-domain MVDR/coherence)\n",
    "\n",
    "Outputs:\n",
    "- Velocity-vs-frequency images for both methods\n",
    "- Simple ridge-contrast metric to quantify improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e70b49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v_of_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mv_of_f\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'v_of_f' is not defined"
     ]
    }
   ],
   "source": [
    "v_of_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c13a44d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic ridge contrast: ReMi=5.92, Ce-ReMi=1.02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import rfft, irfft, rfftfreq\n",
    "\n",
    "# --- 1) Synthetic data generator (coherent dispersive packet) ---\n",
    "def synth_linear_array(\n",
    "    num_channels=201, aperture_m=200.0, fs=100.0, dur_s=600.0,\n",
    "    vmin=200.0, vmax=1000.0, fmin=1.0, fmax=20.0,\n",
    "    noise_std=0.05, movers=False, mover_amp=0.5, random_seed=0,\n",
    "    coherent=True, t0=10.0, fc=10.0, bandwidth_hz=12.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a coherent, dispersive surface-wave packet so dispersion is visible in time–distance.\n",
    "    coherent=True uses a Gaussian band around fc with a common time shift t0 and\n",
    "    phase steering exp(-i 2π f p(f) x), producing a visible dispersive wavefront.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "    x = np.linspace(0, aperture_m, num_channels)\n",
    "    t = np.arange(0, dur_s, 1.0/fs)\n",
    "    F = rfftfreq(t.size, d=1/fs)\n",
    "\n",
    "    # Dispersion law v(f): linear between (fmin,vmax) and (fmax,vmin)\n",
    "    v_of_f = np.interp(F, [fmin, fmax], [vmax, vmin])\n",
    "    p_of_f = 1.0 / np.maximum(v_of_f, 1e-6)\n",
    "\n",
    "    # Frequency-domain source amplitude\n",
    "    if coherent:\n",
    "        sigma = bandwidth_hz / 2.355  # FWHM -> sigma\n",
    "        Amp = np.exp(-0.5 * ((F - fc) / max(sigma, 1e-6))**2)\n",
    "        Amp *= (F >= fmin) & (F <= fmax)\n",
    "        phase_src = np.exp(-2j * np.pi * F * t0)  # center time t0\n",
    "    else:\n",
    "        Amp = ((F >= fmin) & (F <= fmax)).astype(float)\n",
    "        phase_src = np.exp(1j * rng.uniform(0, 2*np.pi, size=F.size))\n",
    "\n",
    "    # Build channel spectra with dispersive steering\n",
    "    Xf = np.zeros((num_channels, F.size), dtype=np.complex128)\n",
    "    for n, xn in enumerate(x):\n",
    "        steer = np.exp(-2j * np.pi * F * p_of_f * xn)\n",
    "        Xf[n] = Amp * phase_src * steer\n",
    "\n",
    "    sfc = irfft(Xf, axis=1)\n",
    "\n",
    "    # Add white noise\n",
    "    sfc += noise_std * rng.standard_normal(sfc.shape)\n",
    "\n",
    "    # Optional non-stationary movers\n",
    "    if movers:\n",
    "        n_movers = 2\n",
    "        for k in range(n_movers):\n",
    "            t0m = rng.uniform(5, dur_s-5)\n",
    "            v_move = rng.uniform(200, 1000)\n",
    "            f_move = rng.uniform(5, 15)\n",
    "            for n, xn in enumerate(x):\n",
    "                tau = (xn / v_move)\n",
    "                w = np.exp(-0.5 * ((t - (t0m + tau))/1.0)**2)\n",
    "                sfc[n] += mover_amp * w * np.sin(2*np.pi*f_move*(t - (t0m + tau)))\n",
    "\n",
    "    return x, t, sfc\n",
    "\n",
    "# --- 2) Baseline ReMi (Bartlett) ---\n",
    "def remi_bartlett_power(sfc, x, fs, slowness_grid, fmin, fmax):\n",
    "    # FFT per channel\n",
    "    X = rfft(sfc, axis=1)\n",
    "    F = rfftfreq(sfc.shape[1], d=1/fs)\n",
    "    fmask = (F >= fmin) & (F <= fmax)\n",
    "    X = X[:, fmask]\n",
    "    Fsel = F[fmask]\n",
    "\n",
    "    # Steering and Bartlett power\n",
    "    P = slowness_grid.size\n",
    "    S = np.zeros((Fsel.size, P))\n",
    "    for k, fk in enumerate(Fsel):\n",
    "        a = np.exp(-2j*np.pi*fk*slowness_grid[None,:]*x[:,None])  # [N,P]\n",
    "        S[k] = np.abs(np.einsum('n,np->p', X[:,k], np.conjugate(a)))**2\n",
    "    # Normalize per-frequency\n",
    "    S /= (np.mean(S, axis=1, keepdims=True) + 1e-12)\n",
    "    return Fsel, S\n",
    "\n",
    "# --- 3) Ce-ReMi (correlation MVDR) ---\n",
    "def cermi_mvdr_power(sfc, x, fs, slowness_grid, fmin, fmax):\n",
    "    from numpy.linalg import LinAlgError\n",
    "\n",
    "    X = rfft(sfc, axis=1)\n",
    "    F = rfftfreq(sfc.shape[1], d=1/fs)\n",
    "    fmask = (F >= fmin) & (F <= fmax)\n",
    "    X = X[:, fmask]\n",
    "    Fsel = F[fmask]\n",
    "\n",
    "    # Phase-only normalization\n",
    "    X = X / (np.abs(X) + 1e-12)\n",
    "\n",
    "    # CSM\n",
    "    R = np.einsum('nf,mf->fmn', X, np.conjugate(X)) / X.shape[1]\n",
    "\n",
    "    # MVDR per frequency\n",
    "    P = slowness_grid.size\n",
    "    S = np.zeros((Fsel.size, P))\n",
    "    for k, fk in enumerate(Fsel):\n",
    "        Rf = R[k]\n",
    "        N = Rf.shape[0]\n",
    "        Rr = Rf + 1e-3 * np.trace(Rf).real / max(N,1) * np.eye(N)\n",
    "        a = np.exp(-2j*np.pi*fk*slowness_grid[None,:]*x[:,None])  # [N,P]\n",
    "        try:\n",
    "            RiA = np.linalg.solve(Rr, a)\n",
    "        except LinAlgError:\n",
    "            RiA = a\n",
    "        denom = np.sum(np.conjugate(a) * RiA, axis=0).real + 1e-18\n",
    "        S[k] = 1.0 / denom\n",
    "    S /= (np.mean(S, axis=1, keepdims=True) + 1e-12)\n",
    "    return Fsel, S\n",
    "\n",
    "# --- 4) Run experiment ---\n",
    "x, t, sfc = synth_linear_array(coherent=True, movers=False, noise_std=0.05, fc=10.0, bandwidth_hz=12.0)\n",
    "fs_syn = 1.0 / np.median(np.diff(t))\n",
    "\n",
    "p_grid = np.linspace(1/800.0, 1/120.0, 161)\n",
    "fmin, fmax = 2.0, 20.0\n",
    "\n",
    "F_re, S_re = remi_bartlett_power(sfc, x, fs_syn, p_grid, fmin, fmax)\n",
    "F_ce, S_ce = cermi_mvdr_power(sfc, x, fs_syn, p_grid, fmin, fmax)\n",
    "\n",
    "V = 1.0 / p_grid\n",
    "\n",
    "# Prepare images as [velocity, frequency]\n",
    "S_re_vy = S_re.T\n",
    "S_ce_vy = S_ce.T\n",
    "\n",
    "# Common color scale\n",
    "vmax = np.nanmax([np.percentile(S_re_vy, 99), np.percentile(S_ce_vy, 99)])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "im0 = ax[0].imshow(S_re_vy, aspect='auto', origin='lower',\n",
    "                   extent=[F_re[0], F_re[-1], V.min(), V.max()], cmap='plasma', vmin=0, vmax=vmax)\n",
    "ax[0].set_title('Synthetic - Original ReMi')\n",
    "ax[0].set_xlabel('Frequency (Hz)'); ax[0].set_ylabel('Velocity (m/s)'); ax[0].invert_yaxis()\n",
    "fig.colorbar(im0, ax=ax[0])\n",
    "\n",
    "im1 = ax[1].imshow(S_ce_vy, aspect='auto', origin='lower',\n",
    "                   extent=[F_ce[0], F_ce[-1], V.min(), V.max()], cmap='plasma', vmin=0, vmax=vmax)\n",
    "ax[1].set_title('Synthetic - Ce-ReMi (MVDR)')\n",
    "ax[1].set_xlabel('Frequency (Hz)'); ax[1].set_ylabel('Velocity (m/s)'); ax[1].invert_yaxis()\n",
    "fig.colorbar(im1, ax=ax[1])\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Contrast metric\n",
    "rc_re = np.nanmean(np.nanmax(S_re, axis=1) / (np.nanmedian(S_re, axis=1) + 1e-12))\n",
    "rc_ce = np.nanmean(np.nanmax(S_ce, axis=1) / (np.nanmedian(S_ce, axis=1) + 1e-12))\n",
    "print(f\"Synthetic ridge contrast: ReMi={rc_re:.2f}, Ce-ReMi={rc_ce:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8405e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize synthetic time–distance data ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure synthetic variables exist (run the synthetic cell first)\n",
    "assert 'x' in globals() and 't' in globals() and 'sfc' in globals(), \"Run the synthetic generation cell first.\"\n",
    "\n",
    "# 1) Waterfall image (distance vs time)\n",
    "vmax = np.percentile(np.abs(sfc), 99)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(\n",
    "    sfc,\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    extent=[float(t[0]), float(t[-1]), float(x[0]), float(x[-1])],\n",
    "    cmap='seismic', vmin=-vmax, vmax=vmax,\n",
    ")\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Distance (m)')\n",
    "plt.title('Synthetic waterfall (time vs distance)')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 2) Selected normalized traces (stacked)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "num_show = 8\n",
    "chan_idx = np.linspace(0, sfc.shape[0] - 1, num_show, dtype=int)\n",
    "for k, ci in enumerate(chan_idx):\n",
    "    tr = sfc[ci]\n",
    "    tr = tr / (np.max(np.abs(tr)) + 1e-12)\n",
    "    ax.plot(t, tr + k * 1.6, lw=0.8, label=f'x={x[ci]:.0f} m')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Selected normalized traces (offset for visibility)')\n",
    "ax.legend(ncol=2, fontsize=8, frameon=False)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) Spectrogram of a mid-channel\n",
    "mid = sfc.shape[0] // 2\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "Pxx, f_spec, t_spec, im = ax.specgram(sfc[mid], NFFT=256, Fs=float(1.0/np.median(np.diff(t))), noverlap=128, cmap='magma')\n",
    "ax.set_ylim(0, 40)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Frequency (Hz)')\n",
    "ax.set_title(f'Spectrogram (mid-channel at x={x[mid]:.0f} m)')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e960ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 6000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dascore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
